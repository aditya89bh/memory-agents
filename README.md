# ğŸ§  Memory Agents â€“ From Continuity to Cognition

This repository is a **progressive exploration of memory systems for AI agents**.

The goal is not to build a single â€œchatbot with memoryâ€, but to **systematically design, implement, and understand memory as a cognitive system**â€”the same way humans use memory for continuity, planning, learning, and identity.

Each project builds on the previous one. Nothing is skipped. Nothing is hidden behind frameworks.

---

## Why Memory Agents?

Most AI systems today are stateless, reactive, short-lived, and context-fragile.

Real intelligence requires **memory**:
- memory of the past  
- memory of what matters  
- memory that shapes future decisions  

This repository treats memory as a **first-class design problem**, not a feature toggle.

---

## Project Overview

Project 1 â†’ continuity  
Project 2 â†’ retrieval & judgment  
Project 3 â†’ integration  
Project 4 â†’ planning  
Project 5 â†’ learning  
Project 6 â†’ identity  
Project 7 â†’ embodiment

---

## ğŸ“˜ Project 1 â€“ Short-Term Memory (Continuity)

**Goal:**  
Give the agent continuity across turns.

**Whatâ€™s built:**
- Rolling window memory  
- Explicit forgetting  
- Deterministic context size  

**Key insight:**  
Memory is not what you store.  
Memory is **what you choose to forget**.

ğŸ“ `project-1-short-term-memory/`

---
## ğŸ“˜ Project 1B â€“ Summary Memory (Compression)

**Goal:**  
Prevent context explosion while preserving meaning.

**Whatâ€™s built:**
- Two-tier memory (recent buffer + running summary)  
- No recursive memory bloat  

**Key insight:**  
Chronology does not scale.  
**Compression is intelligence.**

ğŸ“ `project-1b-summary-memory/`

---

## ğŸ“˜ Project 2 â€“ Long-Term Memory (Retrieval)

**Goal:**  
Move from recent context to **searchable experience**.

Project 2 is broken into focused sub-projects.

**2A â€“ Vector Recall**
- TF-IDF embeddings  
- Cosine similarity  
- Top-k semantic recall  

**Question answered:**  
Can the agent recall relevant past information at all?

**2B â€“ Metadata-Aware Memory**
- Memory types (identity, preference, goal, fact)  
- Tags, sources, filters  

**Question answered:**  
Which memories should be considered right now?

**2C â€“ Salience & Memory Gating**
- Importance scoring  
- Store vs discard decisions  
- Pinned memories  

**Question answered:**  
What is worth remembering long-term?

**2D â€“ Neural Embeddings**
- Sentence Transformers  
- Paraphrase-robust recall  

**Question answered:**  
Can recall feel semantic instead of keyword-based?

ğŸ“ `project-2-long-term-memory/`

---

## ğŸ“˜ Project 3 â€“ Unified Memory Stack (Integration)

**Goal:**  
Make memory feel like **one brain**, not multiple modules.

**Whatâ€™s built:**
- Unified `MemoryManager`  
- Clear read/write phases  
- Single context assembly pipeline  

**Architecture flow:**

Input â†’ Memory Gate â†’ Short-Term Buffer â†’ Summary Memory â†’  
Long-Term Retrieval â†’ Context Assembly â†’ Agent Reasoning

**Why this matters:**  
This is the minimum viable real agent architecture.

ğŸ“ `project-3-unified-memory-stack/`

---

## ğŸ“˜ Project 4 â€“ Memory + Planning (Cognition)

**Goal:**  
Make memory influence **decisions**, not just answers.

**Whatâ€™s built:**
- Action history memory  
- Outcome memory (success / failure)  
- Planner that consults past experience  

**Example:**  
â€œLast time this failed, try a different strategy.â€

ğŸ“ `project-4-memory-planning/`

---

## ğŸ“˜ Project 5 â€“ Skill & Task Memory (Learning)

**Goal:**  
Turn repetition into reusable competence.

**Whatâ€™s built:**
- Task attempt memory  
- Skill abstraction  
- Task-to-skill mapping  

**Example:**  
â€œThis looks like a task Iâ€™ve done before.â€

ğŸ“ `project-5-skill-memory/`

---

## ğŸ“˜ Project 6 â€“ Identity & Personality Memory

**Goal:**  
Make the agent consistent across weeks and months.

**What will be built:**
- Stable identity memory  
- Long-term preferences  
- Trait resolution logic  

**Example:**  
â€œThis user prefers concise answers and Python-first solutions.â€

ğŸ“ `project-6-identity-memory/`

---

## ğŸ“˜ Project 7 â€“ Embodied / World Memory

**Goal:**  
Tie memory to environments, not just text.

**Possible directions:**
- Robotics world memory  
- Simulated environments  
- State- or spatial-aware memory  

**Example:**  
â€œIn this environment, path B was safer last time.â€

ğŸ“ `project-7-embodied-memory/`

---

## Design Principles

- Memory is explicit, never implicit  
- Retrieval happens before reasoning  
- Forgetting is a feature  
- Salience beats volume  
- Minimal frameworks, maximum clarity  
- Colab-first, GitHub-second  

---

## Status

- Projects 1â€“5: âœ… Completed  
- Projects 6â€“7: ğŸ§­ Planned  

---

If someone reads just this README, they should understand **how memory evolves into intelligence**.
